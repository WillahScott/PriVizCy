{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Data Processing  \n",
    "\n",
    "For the network dat visualization we need two datasets (which we will load into [Gephi](https://gephi.org/) to process and export into GEXF format):  \n",
    "* **a Node file** - containing a list of all available nodes, along with possible node information: the url class  \n",
    "* **an Edge file** - containing a list of all edges between the nodes. Each entry will contain an edgeId, the nodes it connects, a weight (the number of cross-site cookies connecting the nodes) and a tag (the names of the baseDomains of the cookies that connect the nodes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Connect to SQLite database\n",
    "con = sqlite3.connect(\"../data/top_100_shallow_1.sqlite\")\n",
    "cur = con.cursor()\n",
    "\n",
    "# Get URL classes from websites_classification.csv\n",
    "websites = pd.read_csv('../data/websites-classification.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://google.com</td>\n",
       "      <td>Search Engines and Portals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://youtube.com</td>\n",
       "      <td>Streaming Media</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://facebook.com</td>\n",
       "      <td>Social Networking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://msn.com</td>\n",
       "      <td>Search Engines and Portals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://yelp.com</td>\n",
       "      <td>Reference</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   url                       class\n",
       "0    http://google.com  Search Engines and Portals\n",
       "1   http://youtube.com             Streaming Media\n",
       "2  http://facebook.com           Social Networking\n",
       "3       http://msn.com  Search Engines and Portals\n",
       "4      http://yelp.com                   Reference"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "websites.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is actually the **nodes_network_data** file we are looking for. Let's just copy it over to processed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!cp ../data/websites-classification.csv ../data/processed/nodes_network_data.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to obtain the edges_network_data file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_result = pd.read_sql_query('SELECT DISTINCT page_url, baseDomain FROM profile_cookies', con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_url</th>\n",
       "      <th>baseDomain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://google.com</td>\n",
       "      <td>google.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://youtube.com</td>\n",
       "      <td>youtube.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://youtube.com</td>\n",
       "      <td>doubleclick.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://youtube.com</td>\n",
       "      <td>pointroll.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://youtube.com</td>\n",
       "      <td>mookie1.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             page_url       baseDomain\n",
       "0   http://google.com       google.com\n",
       "1  http://youtube.com      youtube.com\n",
       "2  http://youtube.com  doubleclick.net\n",
       "3  http://youtube.com    pointroll.com\n",
       "4  http://youtube.com      mookie1.com"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_edges = _result.drop_duplicates()\n",
    "pre_edges.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Group by baseDomain\n",
    "by_domain = pre_edges.groupby('baseDomain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created a total of:  2143 edges\n"
     ]
    }
   ],
   "source": [
    "# initialize edge list\n",
    "edge_dict = {}\n",
    "\n",
    "# For each baseDomain\n",
    "for bd, df in by_domain['page_url']:\n",
    "    edges = combinations(df.values, 2) # iterable of all possible 2 element combinations\n",
    "    for e in edges:\n",
    "        label = tuple(e)\n",
    "        try:\n",
    "            old_weight, old_doms = edge_dict[label]\n",
    "            edge_dict[label] = [old_weight + 1, old_doms + ' | ' + bd]\n",
    "        except KeyError:\n",
    "            edge_dict[label] = [1, bd]\n",
    "\n",
    "print(\"Created a total of: \", len(edge_dict), \"edges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Dump the dictionary into a dataframe (-> csv)\n",
    "pre_df = [ [k[0], k[1], v[0], v[1]] for k,v in edge_dict.items() ]\n",
    "edge_data = pd.DataFrame(pre_df, columns=['node1', 'node2', 'weight', 'tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>edgeID</th>\n",
       "      <th>node1</th>\n",
       "      <th>node2</th>\n",
       "      <th>weight</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>http://aol.com</td>\n",
       "      <td>http://imdb.com</td>\n",
       "      <td>2</td>\n",
       "      <td>doubleclick.net | twitter.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>http://dose.com</td>\n",
       "      <td>http://guff.com</td>\n",
       "      <td>1</td>\n",
       "      <td>scorecardresearch.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>http://urbandictionary.com</td>\n",
       "      <td>http://topix.com</td>\n",
       "      <td>16</td>\n",
       "      <td>adform.net | adgrx.com | bidswitch.net | bluek...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>http://aol.com</td>\n",
       "      <td>http://sbnation.com</td>\n",
       "      <td>17</td>\n",
       "      <td>adadvisor.net | adsrvr.org | adtechus.com | ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>http://pinterest.com</td>\n",
       "      <td>http://eonline.com</td>\n",
       "      <td>2</td>\n",
       "      <td>facebook.com | pinterest.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   edgeID                       node1                node2  weight  \\\n",
       "0       0              http://aol.com      http://imdb.com       2   \n",
       "1       1             http://dose.com      http://guff.com       1   \n",
       "2       2  http://urbandictionary.com     http://topix.com      16   \n",
       "3       3              http://aol.com  http://sbnation.com      17   \n",
       "4       4        http://pinterest.com   http://eonline.com       2   \n",
       "\n",
       "                                                 tag  \n",
       "0                      doubleclick.net | twitter.com  \n",
       "1                              scorecardresearch.com  \n",
       "2  adform.net | adgrx.com | bidswitch.net | bluek...  \n",
       "3  adadvisor.net | adsrvr.org | adtechus.com | ad...  \n",
       "4                       facebook.com | pinterest.com  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_data['edgeID'] = edge_data.index\n",
    "edge_data = edge_data[[ 'edgeID', 'node1', 'node2', 'weight', 'tag' ]]\n",
    "edge_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! This is exactly what we need for the **edge_network_data** file. Let's save it into a .csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "edge_data.to_csv('../data/processed/edge_network_data.csv', index_label=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
