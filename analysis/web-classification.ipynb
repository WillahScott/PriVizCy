{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Classification - Exploration  \n",
    "\n",
    "\n",
    "## Get websites to classify\n",
    "Imports and connect to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Connect to SQLite database\n",
    "con = sqlite3.connect(\"../data/top_100_shallow_1.sqlite\")\n",
    "\n",
    "cur = con.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query to obtain all the 100 top sites visited from the table `CrawlHistory` (see the **DB_explore.ipynb** notebook for details on this table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "websites = pd.read_sql_query(\"SELECT DISTINCT arguments FROM CrawlHistory;\", con)\n",
    "\n",
    "websites.rename(columns={'arguments':'url'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      http://google.com\n",
       "1     http://youtube.com\n",
       "2    http://facebook.com\n",
       "3         http://msn.com\n",
       "4        http://yelp.com\n",
       "5        http://bing.com\n",
       "6     http://twitter.com\n",
       "7      http://amazon.com\n",
       "8    http://buzzfeed.com\n",
       "9     http://answers.com\n",
       "Name: url, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "websites['url'][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Get Classifications  \n",
    "\n",
    "For this we will use a simple class we have created that uses selenium webdriver to query `fortiguard.com` to obtain the classification of a website.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from WebClassifier import WebClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us start with a simple use case with a \"normal\" browser (Firefox)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Newsgroups and Message Boards'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wc = WebClassifier(invisible=False)\n",
    "wc.get_classification('reddit.com')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firefox opened up and we got our classification. Let's try with a list of 10 websites..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classifying 10 URLs. Fetching ...\n",
      "   - PROGRESS: ####################  DONE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Search Engines and Portals',\n",
       " 'Streaming Media',\n",
       " 'Social Networking',\n",
       " 'Search Engines and Portals',\n",
       " 'Reference',\n",
       " 'Search Engines and Portals',\n",
       " 'Social Networking',\n",
       " 'Shopping',\n",
       " 'Entertainment',\n",
       " 'Reference']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wc.get_classifications(websites['url'][:10], verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty fast!  \n",
    "\n",
    "However, since we want to obtain a reasonably large list, there is no need to watch Firefox do everything. Let's use a headless browser ([PhantomJS](http://phantomjs.org/)) for this one..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classifying 100 URLs. Fetching ...\n",
      "   - PROGRESS: ####################  DONE\n"
     ]
    }
   ],
   "source": [
    "wc2 = WebClassifier()\n",
    "\n",
    "websites['class'] = wc2.get_classifications(websites['url'], verbose=True)\n",
    "wc2.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Got it! Let's take a look at what we got "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "News and Media                   18\n",
       "Entertainment                    18\n",
       "Reference                         9\n",
       "Search Engines and Portals        8\n",
       "Information Technology            7\n",
       "Shopping                          5\n",
       "Personal Websites and Blogs       5\n",
       "Finance and Banking               3\n",
       "Health and Wellness               3\n",
       "Business                          3\n",
       "Newsgroups and Message Boards     3\n",
       "Streaming Media                   2\n",
       "File Sharing and Storage          2\n",
       "Arts and Culture                  2\n",
       "Sports                            2\n",
       "Adult Materials                   2\n",
       "Social Networking                 2\n",
       "Travel                            1\n",
       "Job Search                        1\n",
       "Auction                           1\n",
       "Education                         1\n",
       "Web Hosting                       1\n",
       "Political Organizations           1\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "websites['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get third-party cookie coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
